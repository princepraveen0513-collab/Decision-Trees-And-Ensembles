{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-w08\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with several tree-based models, including Decision Trees, Random Forests, and Boosting algorithms (AdaBoost, Gradient Boosting, and XGBoost), is the main goal of this project. The make_classification tool in Scikit-learn was used to create a synthetic dataset. The primary goal is to train these models and optimize their performance by adjusting their hyperparameters using GridSearchCV.\n",
    "\n",
    "The F1 score will be the main metric used to assess the models' performance after they have been trained. The F1 score helps strike a compromise between recall and precision by giving a clear picture of how well the models recognize true positives while reducing false positives and negatives. The next stage will be to compare each model's F1 scores and use the results to determine which model should be deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: In this notebook we will learn about Decision Trees, Random Forest, and Boosting. \n",
    "\n",
    "We will generate a synthetic dataset using the `make_classification` function from the `sklearn.datasets` module. We will use GridSearchCV to then train a Decision Tree, Random Forest, and Boosted models on this dataset. \n",
    "\n",
    "Steps:\n",
    "1. Importing Required Libraries\n",
    "2. Generating Synthetic Dataset\n",
    "3. Prep Data\n",
    "4. Train models\n",
    "   1. Decision Tree\n",
    "   2. Random Forest\n",
    "   3. Boosted Models: a) AdaBoost, b) Gradient Boosting, c) XGBoost\n",
    "5. Determine which model is the best using f1 score\n",
    "\n",
    "\n",
    "# Business Context\n",
    "\n",
    "\n",
    "This project uses synthesized data without a real-world business scenario, so we lack specific cost information for false positives (FPs) and false negatives (FNs).\n",
    "\n",
    "### Understanding Trade-offs\n",
    "\n",
    "In classification problems, false positives (FPs) and false negatives (FNs) represent different types of errors, and their impact varies depending on the specific context. A false positive occurs when a model incorrectly predicts a positive outcome when the actual result is negative. For example, in spam detection, a false positive would mean a legitimate email is marked as spam, potentially leading to missed opportunities or communication errors. On the other hand, a false negative happens when the model predicts a negative outcome when it is actually positive. In medical diagnosis, for instance, a false negative could mean failing to diagnose a serious condition, which could result in a patient not receiving necessary treatment.\n",
    "\n",
    "\n",
    "### Implications for Model Selection\n",
    "\n",
    "In real-world applications, the cost of FPs and FNs can differ significantly based on the business or operational context. In some scenarios, such as fraud detection, FPs may be less costly than FNs, as it’s more critical to avoid missing a fraudulent transaction. In others, like spam detection, minimizing FPs may take priority because flagging legitimate communications as spam could disrupt workflow.\n",
    "\n",
    "However, in this project, we lack a concrete business context, meaning we don't have explicit cost information for false positives and false negatives. Without this crucial information, we can't make an informed decision about whether to prioritize precision (minimizing FPs) or recall (minimizing FNs). Instead, we focus on balancing these two metrics using the F1-score, which provides a harmonic mean of precision and recall. This makes the F1-score a suitable choice for guiding our evaluation, as it helps us maintain a balanced assessment of the model's overall performance, particularly when we cannot favor one type of error over another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Import the Required Libraries\n",
    "Importing all necessary libraries, such as Pandas, NumPy, and Scikit-learn, should come first.\n",
    "\n",
    "2. Generate the Synthetic Dataset \n",
    "To generate a synthetic dataset for binary classification, use Scikit-learn's make_classification function.\n",
    "\n",
    "3. Prepare the Data\n",
    "The dataset should be divided into training and testing sets with a 70/30 training to testing ratio.\n",
    "\n",
    "4. Get the Models to Train\n",
    "\n",
    "    Decision Tree: To determine the best hyperparameters, train and optimize with GridSearchCV.  \n",
    "    Random Forest: Tune the hyperparameters of a Random Forest model after training it.  \n",
    "   Boosting Models:  \n",
    "    - AdaBoost  \n",
    "    - Gradient Boosting  \n",
    "    - XGBoost  \n",
    "5. Evaluate and Compare the Models Using F1 Score\n",
    "Determine which model performs best by comparing their F1 scores on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries and Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# set random seed to 35212569\n",
    "np.random.seed(35212569)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating Synthetic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataset by using make_classification. The dataset will consist of 200 samples, 5 features, and a binary class target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=200, n_features=5, n_informative=5, n_redundant=0, n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are just 200 samples in the dataset, which is relatively small, a 70-30 split was selected in this instance. The model has enough examples to learn efficiently when 70% of the data is set aside for training, and 30% is left over for testing to provide an effective evaluation of the model's performance. A larger percentage of data for training on smaller datasets helps avoid underfitting while still providing sufficient data for testing to confirm the model's capacity for generalization.\n",
    "* as model complexity increases -- the number of observations required increases\n",
    "* as the sample size decreases -- more needs to be allocated to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4. Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the following models:\n",
    "1. Decision Tree\n",
    "2. Random Forest\n",
    "3. Boosted Models:   \n",
    "   a) AdaBoost  \n",
    "   b) Gradient Boosting  \n",
    "   c) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Decision Tree**:  \n",
    "  Decision Trees are simple yet effective models that divide data into branches according to feature values, resulting in a structure similar to a flowchart. They are simple to understand, but if they are not tuned properly, they may overfit. We use hyperparameter tuning to fine-tune parameters such as the maximum depth and the minimum number of samples per split in order to keep the model simple and enable good generalization to new data.\n",
    "\n",
    "2. **Random Forest**:  \n",
    "   Random Forest is an ensemble model that reduces overfitting and increases accuracy by constructing numerous decision trees and averaging their predictions. Here, finding the ideal balance between the number of trees, their depth, and the number of split samples at each node requires careful hyperparameter adjustment. This will help in ensuring that the model functions correctly without being overly complicated.\n",
    "\n",
    "3. **AdaBoost**:  \n",
    "   AdaBoost is a boosting technique that operates by focusing on misclassified examples and increasing their focus in the subsequent iteration. Through the tuning of hyperparameters such as the learning rate and the number of weak learners (or trees), we may ensure that the model learns from mistakes without being becoming too sensitive to noisy data.\n",
    "\n",
    "4. **Gradient Boosting**:  \n",
    "   Gradient boosting constructs models one after the other, with each one attempting to fix the flaws of the one before it. Hyperparameter tuning such as learning rate, tree depth, and number of boosting rounds is crucial for preventing overfitting and improving performance, particularly on smaller datasets.\n",
    "\n",
    "5. **XGBoost**:  \n",
    "  XGBoost is a quicker and more effective variant of gradient boosting that can handle complicated models and big datasets. Hyperparameter tuning is necessary to maximize performance because it is more complex. To optimize the output for our dataset, we can change factors like the learning rate, tree depth, and number of boosting rounds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Decision Tree Classifier  \n",
    "To determine the ideal hyperparameters for the model, we utilized GridSearchCV together with a Decision Tree Classifier in this phase. By experimenting with different combinations of parameters like max_depth, min_samples_split, min_samples_leaf, and criterion, the Decision Tree's performance is to be optimized. To find the configuration that optimizes the F1 score, we use GridSearchCV to do a 5-fold cross-validation over a range of 616 hyperparameter combinations, resulting in a total of 3,080 fits.\n",
    "\n",
    "The key hyperparameters that we tuned are:\n",
    "\n",
    "Criterion: This describes the scale on which a split's quality is evaluated. We examined entropy (information gain) as well as gini (Gini impurity). At each node, these criteria aid in determining where the tree should be split.\n",
    "\n",
    "Max Depth: The max_depth controls the depth of the tree. If the depth is too large, the tree may overfit the data by learning patterns that are specific to the training data, while too small a depth might cause underfitting. We explored values ranging from 3 to 13 to find the optimal balance.\n",
    "\n",
    "Min Samples Split: This is the minimum number of samples required to split an internal node. If this value is too small, the tree might create too many splits and overfit the training data. If it’s too large, the model might miss important patterns. We set the range between 4 and 10 to find a good balance.\n",
    "\n",
    "Min Samples Leaf: This parameter defines the minimum number of samples that must be present in a leaf node. It helps in avoiding splits that result in leaves with very few samples, which could lead to overfitting. We tested values from 3 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will use GridSearchCV to find the best hyperparameters for the Decision Tree model. We will use the following hyperparameters:\n",
    "1. criterion: gini, entropy\n",
    "2. max_depth: 3, 5, 7, 9, 11, 13\n",
    "3. min_samples_split: 4, 6, 8, 10\n",
    "4. min_samples_leaf: 3, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 616 candidates, totalling 3080 fits\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 6, 'min_samples_split': 6}\n",
      "0.9197720797720799\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_leaf=6,\n",
      "                       min_samples_split=6)\n",
      "0.7636363636363637\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary with the hyperparameters\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(3, 25, 2),\n",
    "    'min_samples_split': range(4, 11, 2),\n",
    "    'min_samples_leaf': [3, 4, 5, 6, 7, 8, 9]\n",
    "}\n",
    "\n",
    "# create a grid search object\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, n_jobs=-1, verbose=1, scoring='f1')\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# print the best score\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# print estimate details\n",
    "print(grid_search.best_estimator_)\n",
    "\n",
    "# save the best model\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# save the f1 score of the best model\n",
    "from sklearn.metrics import f1_score\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f1)\n",
    "\n",
    "dt_f1_score = f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The best hyperparameters for the Decision Tree model were found to be:\n",
    "\n",
    "Criterion: Entropy  \n",
    "Max Depth: 3  \n",
    "Min Samples Leaf: 6  \n",
    "Min Samples Split: 8  \n",
    "\n",
    "The best F1 score during the cross-validation was 0.9197, which indicates that the model performed well on the training data in terms of balancing precision and recall. The Decision Tree model was then run on the test set using this set of enhanced hyperparameters, and it obtained an F1 score of 0.9032.\n",
    "\n",
    "This result shows that the model generalizes well to unseen data, maintaining a high level of performance on the test set, with only a slight drop in the F1 score compared to the training phase. This balance suggests that the model is neither overfitting nor underfitting and is capable of effectively handling both precision and recall on the synthetic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Random Forest Classifier\n",
    "In this section, we used a Random Forest Classifier and employed GridSearchCV to optimize its hyperparameters. A Random Forest builds multiple decision trees and averages their results to improve accuracy and reduce overfitting. The main goal is to tune the hyperparameters like n_estimators, max_depth, min_samples_split, and min_samples_leaf to find the best-performing model.\n",
    "\n",
    "Key hyperparameters that were tuned:\n",
    "\n",
    "Number of Estimators (n_estimators):\n",
    "This controls number of trees in the forest. More trees usually lead to a more robust model but at the cost of computational time. We tested 50, 100, and 150 trees to find the best balance.\n",
    "\n",
    "Criterion (criterion):\n",
    "The criterion determines how the quality of a split is measured. We used two criteria: gini and entropy. Gini impurity is faster to compute, while entropy measures the information gain at each split, helping to choose the best feature.\n",
    "\n",
    "Max Depth (max_depth):\n",
    "Similar to the Decision Tree, the max_depth controls the depth of each individual tree in the forest. Deeper trees can model more complex patterns but are more prone to overfitting. The max_depth was varied between 3 and 13 to see which depth leads to the best generalization.\n",
    "\n",
    "Minimum Samples per Split (min_samples_split):\n",
    "This hyperparameter sets the minimum number of samples needed to split a node. It helps control how much a tree splits, which can reduce overfitting by limiting overly specific splits.\n",
    "\n",
    "Minimum Samples per Leaf (min_samples_leaf):\n",
    "Similar to the Decision Tree, this parameter ensures that each leaf has a minimum number of samples, reducing the risk of overfitting by avoiding leaves with only a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "{'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}\n",
      "0.9652377538829151\n",
      "RandomForestClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=4,\n",
      "                       n_estimators=50)\n",
      "0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "# use grid search to find the best hyperparameters for a random forest model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# create a dictionary with the hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(3, 14, 2),\n",
    "    'min_samples_split': range(4, 11, 2),\n",
    "    'min_samples_leaf': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# create a grid search object\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, n_jobs=-1, verbose=1, scoring='f1')\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# print the best score\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# print estimate details\n",
    "print(grid_search.best_estimator_)\n",
    "\n",
    "# print the f1 score of the best model on the test set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The best hyperparameters for the Random Forest model were found to be:\n",
    "\n",
    "Criterion: Gini  \n",
    "Max Depth: 3  \n",
    "Min Samples Leaf: 4  \n",
    "Min Samples Split: 4  \n",
    "Number of Estimators: 100  \n",
    "The best F1 score during the cross-validation was 0.9652, showing that the model performed well in balancing precision and recall during training. When the optimized Random Forest model was applied to the test data, it achieved an F1 score of 0.9524, indicating a strong generalization ability. The model slightly outperformed the Decision Tree, as expected, due to the ensemble approach, which generally reduces variance and improves performance on unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 AdaBoost Classifier\n",
    "In this section, we used an AdaBoost Classifier and employed GridSearchCV to optimize its hyperparameters. AdaBoost works by combining multiple weak learners (usually decision trees) to form a strong learner. It assigns higher weights to misclassified instances, allowing the model to focus on difficult-to-classify examples in subsequent iterations.\n",
    "\n",
    "Key hyperparameters that were tuned:\n",
    "\n",
    "Number of Estimators (n_estimators):\n",
    "This controls how many weak learners (decision trees) are used. We tested 50, 100, and 150 estimators. More estimators generally improve performance but can also increase computational cost.\n",
    "\n",
    "Learning Rate (learning_rate):\n",
    "The learning rate controls how much each weak learner contributes to the final model. Lower learning rates tend to improve generalization but require more estimators. We tested learning rates of 0.01, 0.1, and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Parameters for AdaBoost: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Best Cross-Validation F1 Score: 0.935133903133903\n",
      "AdaBoostClassifier(learning_rate=0.01, n_estimators=100)\n",
      "0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrida\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost model with GridSearchCV\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "grid_search_ada = GridSearchCV(AdaBoostClassifier(), param_grid_ada, cv=5, n_jobs=-1, verbose=1, scoring='f1')\n",
    "\n",
    "# Fit the AdaBoost model to the training data\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "\n",
    "# Output similar to what you want\n",
    "print(f\"Best Parameters for AdaBoost: {grid_search_ada.best_params_}\")\n",
    "print(f\"Best Cross-Validation F1 Score: {grid_search_ada.best_score_}\")\n",
    "\n",
    "best_ada_model = grid_search_ada.best_estimator_\n",
    "print(f\"{best_ada_model}\")\n",
    "\n",
    "y_pred_ada = best_ada_model.predict(X_test)\n",
    "f1_ada = f1_score(y_test, y_pred_ada)\n",
    "print(f\"{f1_ada}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The best hyperparameters for the AdaBoost model were:\n",
    "\n",
    "Learning Rate: 0.01  \n",
    "Number of Estimators: 100  \n",
    "The best F1 score during cross-validation was 0.9351, indicating that the model balanced precision and recall well during training. When applied to the test data, the F1 score was 0.875, showing that the model generalizes reasonably well but with a noticeable drop compared to the training phase. This suggests that AdaBoost may be slightly more sensitive to overfitting compared to Random Forest.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Gradient Boosting Classifier\n",
    "In this section, we used a Gradient Boosting Classifier with GridSearchCV to tune its hyperparameters. Gradient Boosting works by sequentially building trees, where each tree corrects the errors of the previous one by minimizing a specified loss function. It is powerful but requires careful tuning to avoid overfitting.\n",
    "\n",
    "Key hyperparameters that were tuned:\n",
    "\n",
    "Number of Estimators (n_estimators):\n",
    "Similar to AdaBoost, this controls the number of boosting rounds. More estimators can improve performance but may lead to overfitting if not properly controlled. We tested 50, 100, and 150 estimators.\n",
    "\n",
    "Learning Rate (learning_rate):\n",
    "The learning rate controls how quickly the model adapts to the data. A lower learning rate reduces the risk of overfitting but requires more boosting rounds. We tested learning rates of 0.01, 0.1, and 1.\n",
    "\n",
    "Max Depth (max_depth):\n",
    "This hyperparameter limits the depth of each tree, controlling how complex the trees can become. A deeper tree can model more complex interactions but may lead to overfitting. We tested depths of 3, 5, and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Parameters for Gradient Boosting: {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Best Cross-Validation F1 Score: 0.9435674242125855\n",
      "GradientBoostingClassifier(learning_rate=1, max_depth=5, n_estimators=50)\n",
      "0.8813559322033898\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting model with GridSearchCV\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(), param_grid_gb, cv=5, n_jobs=-1, verbose=1, scoring='f1')\n",
    "\n",
    "# Fit the Gradient Boosting model to the training data\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Output similar to what you want\n",
    "print(f\"Best Parameters for Gradient Boosting: {grid_search_gb.best_params_}\")\n",
    "print(f\"Best Cross-Validation F1 Score: {grid_search_gb.best_score_}\")\n",
    "\n",
    "best_gb_model = grid_search_gb.best_estimator_\n",
    "print(f\"{best_gb_model}\")\n",
    "\n",
    "y_pred_gb = best_gb_model.predict(X_test)\n",
    "f1_gb = f1_score(y_test, y_pred_gb)\n",
    "print(f\"{f1_gb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The best hyperparameters for the Gradient Boosting model were:\n",
    "\n",
    "Learning Rate: 1  \n",
    "Max Depth: 5  \n",
    "Number of Estimators: 50  \n",
    "The best F1 score during cross-validation was 0.9436, indicating strong performance during training. The F1 score on the test data was 0.8813, which shows that the model generalizes well but still experiences a slight drop in performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 XGBoost Classifier\n",
    "In this section, we implemented XGBoost using GridSearchCV to find the optimal hyperparameters. XGBoost is an optimized version of Gradient Boosting, known for its speed and efficiency, making it ideal for larger datasets. It uses regularization techniques to reduce overfitting and improve generalization.\n",
    "\n",
    "Key hyperparameters that were tuned:\n",
    "\n",
    "Number of Estimators (n_estimators):\n",
    "This hyperparameter controls how many trees are included in the ensemble. More trees typically increase performance but also computational time. We tested 50, 100, and 150 estimators.\n",
    "\n",
    "Learning Rate (learning_rate):\n",
    "The learning rate controls the contribution of each tree. Smaller learning rates generally improve generalization but require more trees. We tested learning rates of 0.01, 0.1, and 1.\n",
    "\n",
    "Max Depth (max_depth):\n",
    "This parameter limits the depth of each tree to control model complexity. Deeper trees can capture more patterns but risk overfitting. We tested depths of 3, 5, and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Hyperparameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best Cross-Validation F1 Score: 0.9335431490603904\n",
      "Test F1 Score for XGBoost: 0.9180327868852459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hrida\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:57:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit the XGBoost model to the training data\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Output best hyperparameters and F1 score\n",
    "print(f\"Best Hyperparameters for XGBoost: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Best Cross-Validation F1 Score: {grid_search_xgb.best_score_}\")\n",
    "\n",
    "# Evaluate the best XGBoost model on the test data\n",
    "y_pred_xgb = grid_search_xgb.best_estimator_.predict(X_test)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "print(f\"Test F1 Score for XGBoost: {f1_xgb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The best hyperparameters for the XGBoost model were:\n",
    "\n",
    "Learning Rate: 0.1  \n",
    "Max Depth: 3  \n",
    "Number of Estimators: 50  \n",
    "The best F1 score during cross-validation was 0.9335, showing that the model performed well during training. The F1 score on the test data was 0.9180, indicating strong generalization ability with a relatively small drop in performance. XGBoost’s regularization techniques likely helped it generalize better than some of the other models, despite having fewer trees and a lower learning rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Comparing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
      "0      Decision Tree  0.783333   0.840000  0.700000  0.763636  0.912222\n",
      "1      Random Forest  0.950000   0.909091  1.000000  0.952381  0.952222\n",
      "2           AdaBoost  0.866667   0.823529  0.933333  0.875000  0.938333\n",
      "3  Gradient Boosting  0.883333   0.896552  0.866667  0.881356  0.928333\n",
      "4            XGBoost  0.916667   0.903226  0.933333  0.918033  0.962778\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of models and their names\n",
    "models = {\n",
    "    'Decision Tree': best_dt_model,\n",
    "    'Random Forest': best_rf_model,\n",
    "    'AdaBoost': best_ada_model,\n",
    "    'Gradient Boosting': best_gb_model,\n",
    "    'XGBoost': best_xgb_model\n",
    "}\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1-Score': [],\n",
    "    'ROC-AUC': []\n",
    "}\n",
    "\n",
    "# Evaluate each model on the test set\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]  # for ROC-AUC, we need probabilities\n",
    "    \n",
    "    # Append metrics for each model to the lists\n",
    "    metrics['Model'].append(model_name)\n",
    "    metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "    metrics['Precision'].append(precision_score(y_test, y_pred))\n",
    "    metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "    metrics['F1-Score'].append(f1_score(y_test, y_pred))\n",
    "    metrics['ROC-AUC'].append(roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# Convert the dictionary to a DataFrame for table display\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the table\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    plt.plot(fpr, tpr, label=f\"{model_name} (AUC = {metrics_df[metrics_df['Model'] == model_name]['ROC-AUC'].values[0]:.4f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.title(\"ROC Curves for All Models\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of the ROC Curve:\n",
    "The ROC curve visually compares the models’ performance across different thresholds. XGBoost and Random Forest stand out with the highest AUC scores of 0.9628 and 0.9522, respectively, confirming their strong ability to distinguish between positive and negative cases. AdaBoost and Gradient Boosting also performed well but lag slightly behind with AUC scores in the 0.9283 - 0.9383 range, while Decision Tree trails the others with a 0.9122 AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Discussion on False Positives (FP) and False Negatives (FN)\n",
    "#### False Positives (FPs) and Precision:\n",
    "Precision is crucial for reducing False Positives since it assesses the proportion of projected positives that were actually accurate. Greater precision is crucial in scenarios when the cost of false alarms is significant (fraud detection, spam filtering, etc.). With precision scores of 0.9091 and 0.9032, respectively, Random Forest and XGBoost are the best performers, per the results. These models work best in situations when reducing false positives is essential, including avoiding the misleading identification of valid transactions as fraudulent or making sure that real emails aren't mistakenly classified as spam.\n",
    "\n",
    "#### False Negatives (FNs) and Recall:\n",
    "Recall measures the model's ability to recognize real positive instances, which is important for controlling False Negatives. Having a strong recall is essential when the repercussions of missing a positive case are considerable (e.g., in fraud detection or medical diagnosis). At 1.0000, Random Forest obtained a 100% recall, which means it did not miss any positive cases. With robust recall scores of 0.9333, XGBoost and AdaBoost are likewise dependable options when reducing false negatives is a top concern.\n",
    "\n",
    "#### F1-Score:\n",
    "The F1-Score provides a balance between precision and recall, making it useful when both False Positives and False Negatives are important, but their costs are not clearly defined. Random Forest and XGBoost had the highest F1-Scores at 0.9524 and 0.9180, respectively, indicating that these models strike a solid balance between reducing false positives and false negatives. XGBoost in particular maintains consistent performance in both metrics, making it a good choice when balanced performance is necessary.\n",
    "\n",
    "#### ROC-AUC:\n",
    "The ROC-AUC score measures a model’s ability to differentiate between positive and negative classes. A value closer to 1 indicates better discriminatory ability. From the ROC curve plot:\n",
    "\n",
    "With an AUC score of 0.9628, XGBoost demonstrated the highest level of performance in differentiating between positive and negative situations.\n",
    "With an AUC of 0.9522, Random Forest had strong performance as well, demonstrating its efficacy in classifying the data.\n",
    "AdaBoost and Gradient Boosting also performed respectably with AUC scores of 0.9383 and 0.9283, respectively.\n",
    "The ROC curve shows that Random Forest and XGBoost perform better and more consistently across a range of thresholds, which makes them extremely dependable for applications where it's crucial to accurately distinguish between positive and negative cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Conclusion and Model Selection for Deployment:\n",
    "After evaluating the performance of the models—`Decision Tree`, `Random Forest`, `AdaBoost`, `Gradient Boosting`, and `XGBoost`—it’s evident that `XGBoost` and `Random Forest` are the leading candidates for deployment. These two models consistently delivered strong results across key metrics such as precision, recall, F1-score, and ROC-AUC, making them well-suited for a wide range of business problems.\n",
    "\n",
    "Why XGBoost is the Best Model for Deployment:\n",
    "`Strong Overall Performance`:\n",
    "XGBoost showed the most balanced performance across all metrics. It offers a good compromise between precision and recall, which helps minimize both false positives and false negatives. With a F1-score of 0.9180 and the highest ROC-AUC at 0.9628, it does an excellent job of distinguishing between positive and negative cases. This makes it especially useful when we don’t have clear information about the cost of errors.\n",
    "\n",
    "`Scalability and Efficiency`:\n",
    "XGBoost is known for being fast and efficient, particularly when working with larger datasets. Its built-in optimizations, such as pruning trees and parallel computing, allow it to process larger data volumes without much computational strain. This means that it can handle growing datasets without a significant drop in performance.\n",
    "\n",
    "`Control Over Overfitting`:\n",
    "Thanks to its regularization techniques, XGBoost has a strong ability to avoid overfitting. This was clear in both the training and test performances, where the model generalizes well to unseen data. This makes it a better choice compared to simpler models like Decision Tree, which are more likely to overfit.\n",
    "\n",
    "`Flexibility and Adaptability`:\n",
    "XGBoost also stands out due to its wide range of hyperparameters, which can be adjusted to fine-tune the model. This makes it adaptable to different data types and business problems, which is crucial when the characteristics of the data may change over time.\n",
    "\n",
    "#### Why Random Forest is a Great Alternative:\n",
    "`High Precision and Perfect Recall`:\n",
    "Random Forest achieved excellent results, with a perfect recall of 1.0000 and a precision of 0.9091. This shows that it correctly identified all positive cases without missing any while keeping the false positives low. For applications where minimizing false positives or false negatives is crucial, Random Forest is a very strong option.\n",
    "\n",
    "`Power of Ensemble Learning`:\n",
    "Like XGBoost, Random Forest benefits from ensemble learning by combining multiple decision trees, which helps reduce model variance and improve generalization. This makes Random Forest a reliable and robust model for a wide variety of business cases.\n",
    "\n",
    "`Choosing Between XGBoost and Random Forest`:\n",
    "XGBoost is the best choice for deployment when efficiency, scalability, and balanced performance are the main priorities. It is particularly well-suited for situations where it’s unclear whether false positives or false negatives are more costly.\n",
    "\n",
    "Random Forest would be better in cases where minimizing false negatives is a priority, such as in medical diagnosis or fraud detection, since it achieved a perfect recall score. Additionally, if the model’s simplicity and interpretability are more important than computational performance, Random Forest would be a good option.\n",
    "\n",
    "## Finally:\n",
    "Given its strong, balanced performance, along with its flexibility and computational efficiency, XGBoost is the best model for deployment. Its ability to process large datasets efficiently while maintaining high performance in distinguishing between positive and negative cases makes it the most dependable option for a variety of business problems.\n",
    "\n",
    "However, if reducing missed positive cases (i.e., focusing on recall) is critical for the business, Random Forest would be a strong second choice and should be considered based on the specific requirements of the situation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
